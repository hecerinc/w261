{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoKOtk1ZM284",
        "outputId": "19c3e44a-cdad-460e-cae8-60c31e7a2a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=9ab6766a76f3dab6fe23bb2ce1e8781e2f7c2d816426a3696b1965f7019b47b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "# run this cell as is to install PySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "try:\n",
        "    spark\n",
        "    print(\"Spark is already running\")\n",
        "    print(f\"{sc.master} appName: {sc.appName}\")\n",
        "except NameError:\n",
        "    print('starting Spark')\n",
        "    app_name = 'Week07'\n",
        "    master = \"local[*]\"\n",
        "    spark = SparkSession\\\n",
        "            .builder\\\n",
        "            .appName(app_name)\\\n",
        "            .config('spark.ui.port', '4050')\\\n",
        "            .master(master)\\\n",
        "            .getOrCreate()\n",
        "sc = spark.sparkContext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG-f185zM6ez",
        "outputId": "c354ecf6-2ac6-496f-9416-3b6721f7c476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting Spark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From last week"
      ],
      "metadata": {
        "id": "lUK0ILHdP2aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (RUN THIS CELL AS IS)\n",
        "import re\n",
        "import ast\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Simple linear regression\n",
        "#           X             y\n",
        "X_y =  [[  0.39050803,  -1.20623543],\n",
        "       [  1.72151493,  13.57377242],\n",
        "       [  0.82210701,   5.50818095],\n",
        "       [  0.35906546,  -2.19996366],\n",
        "       [ -0.61076161,  -3.90958845],\n",
        "       [  1.1671529 ,  11.12900159],\n",
        "       [ -0.49930231,  -3.63685934],\n",
        "       [  3.13418401,  22.71362238],\n",
        "       [  3.70930208,  25.53291143]]\n",
        "\n",
        "data_rdd = sc.parallelize(X_y).cache()\n",
        "# The true y = 8x - 2.\n",
        "#.  [b, m]\n",
        "W = [-2, 8]  # model\n",
        "wBroadcast = sc.broadcast(W)  # make available in memory as read-only to the executors (for mappers and reducers)\n",
        "#                                       (               Xw             -     y)**2\n",
        "# gradient  (Xw - y) X\n",
        "MSE  = data_rdd.map(lambda d: (np.dot(np.append(1, d[:-1]), wBroadcast.value) - d[-1])**2).mean()\n",
        "print(f\"MSE:{MSE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udcbt28EP1Lu",
        "outputId": "9091e0b0-1841-4140-e873-37c73a78f410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:5.832730881179018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using packages and Dataframes\n",
        "\n",
        "Next week we will properly introduce Dataframes and how to use them. However, we want it to give a preview on how to use them and how can we use MLlib to train our model (Question 9 of HW04!)\n",
        "\n",
        "## Dataframes\n",
        "\n",
        "We can transform any RDD into a Dataframe by a simple command [Click here for the API](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html)"
      ],
      "metadata": {
        "id": "sryQJGXVPhTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple command to transform a RDD to Dataframe\n",
        "# If you want to name the columns of the RDD\n",
        "columns = ['X', 'y']\n",
        "data_df = data_rdd.toDF(columns)\n",
        "data_df.toPandas() #If the DF is the result of an aaggregation, you can transform it to Pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "szSVlEcoNB4t",
        "outputId": "b9e9a8b5-50cf-407a-ca3b-1b5f45df1888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          X          y\n",
              "0  0.390508  -1.206235\n",
              "1  1.721515  13.573772\n",
              "2  0.822107   5.508181\n",
              "3  0.359065  -2.199964\n",
              "4 -0.610762  -3.909588\n",
              "5  1.167153  11.129002\n",
              "6 -0.499302  -3.636859\n",
              "7  3.134184  22.713622\n",
              "8  3.709302  25.532911"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14b8523f-c7d5-420d-a6b9-cc0d5a722e15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.390508</td>\n",
              "      <td>-1.206235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.721515</td>\n",
              "      <td>13.573772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.822107</td>\n",
              "      <td>5.508181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.359065</td>\n",
              "      <td>-2.199964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.610762</td>\n",
              "      <td>-3.909588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.167153</td>\n",
              "      <td>11.129002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.499302</td>\n",
              "      <td>-3.636859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.134184</td>\n",
              "      <td>22.713622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.709302</td>\n",
              "      <td>25.532911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14b8523f-c7d5-420d-a6b9-cc0d5a722e15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14b8523f-c7d5-420d-a6b9-cc0d5a722e15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14b8523f-c7d5-420d-a6b9-cc0d5a722e15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark SQL\n",
        "\n",
        "Dataframe API is very similar to Spark SQL [Link Here.](https://spark.apache.org/docs/latest/sql-programming-guide.html) You can use `select(), filter(), and more`"
      ],
      "metadata": {
        "id": "BPvAU5HlQJJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Adding a new column\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "data_df = data_df.withColumn('2X', 2*col('X'))"
      ],
      "metadata": {
        "id": "HKZ56h5a33DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using MLLib\n",
        "\n",
        "To use MLLib we need to first create a Vector Assembler (that create a vector of features). Then, we can call it similar to `scikit-learn`\n",
        "\n",
        "### Step 1: Vector Assembler"
      ],
      "metadata": {
        "id": "OrBLbT_YQNWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "features = ['X', '2X']\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "data_df_VA = assembler.transform(data_df)\n",
        "data_df_VA.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5AeW175QQmh",
        "outputId": "fa0e3f47-a6ae-411e-905e-02e434ff96b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+--------------------+\n",
            "|          X|          y|         2X|            features|\n",
            "+-----------+-----------+-----------+--------------------+\n",
            "| 0.39050803|-1.20623543| 0.78101606|[0.39050803,0.781...|\n",
            "| 1.72151493|13.57377242| 3.44302986|[1.72151493,3.443...|\n",
            "| 0.82210701| 5.50818095| 1.64421402|[0.82210701,1.644...|\n",
            "| 0.35906546|-2.19996366| 0.71813092|[0.35906546,0.718...|\n",
            "|-0.61076161|-3.90958845|-1.22152322|[-0.61076161,-1.2...|\n",
            "|  1.1671529|11.12900159|  2.3343058|[1.1671529,2.3343...|\n",
            "|-0.49930231|-3.63685934|-0.99860462|[-0.49930231,-0.9...|\n",
            "| 3.13418401|22.71362238| 6.26836802|[3.13418401,6.268...|\n",
            "| 3.70930208|25.53291143| 7.41860416|[3.70930208,7.418...|\n",
            "+-----------+-----------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Scale the date\n",
        "\n",
        "Similar to `scikit-learn`, MLLib have a scaler to scale the data. Its logic is very similar to Vector Assembler. You can specify if you want to scale only by standard deviation (default) or if you want to compute a `Z-score` (flag `withMean = True`)"
      ],
      "metadata": {
        "id": "lrQbHMU9QbJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "scaler = StandardScaler(withMean = True).setInputCol('features').setOutputCol(\"features_scaled\").fit(data_df_VA)\n",
        "data_df_VA_SC = scaler.transform(data_df_VA)\n",
        "data_df_VA_SC.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HsjWY9KRG1r",
        "outputId": "f9f4fbcc-1c43-4f30-b029-1ab304f8e6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+--------------------+--------------------+\n",
            "|          X|          y|         2X|            features|     features_scaled|\n",
            "+-----------+-----------+-----------+--------------------+--------------------+\n",
            "| 0.39050803|-1.20623543| 0.78101606|[0.39050803,0.781...|[-0.4955596577609...|\n",
            "| 1.72151493|13.57377242| 3.44302986|[1.72151493,3.443...|[0.39322065840177...|\n",
            "| 0.82210701| 5.50818095| 1.64421402|[0.82210701,1.644...|[-0.2073592901295...|\n",
            "| 0.35906546|-2.19996366| 0.71813092|[0.35906546,0.718...|[-0.5165554447140...|\n",
            "|-0.61076161|-3.90958845|-1.22152322|[-0.61076161,-1.2...|[-1.1641578049255...|\n",
            "|  1.1671529|11.12900159|  2.3343058|[1.1671529,2.3343...|[0.02304522182666...|\n",
            "|-0.49930231|-3.63685934|-0.99860462|[-0.49930231,-0.9...|[-1.0897308189397...|\n",
            "| 3.13418401|22.71362238| 6.26836802|[3.13418401,6.268...|[1.33653092340163...|\n",
            "| 3.70930208|25.53291143| 7.41860416|[3.70930208,7.418...|[1.72056621283963...|\n",
            "+-----------+-----------+-----------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Fit model\n",
        "The `LinearRegression` method covers both standard Linear Regression (default) or both LASSO and Ridge (0 Corresponds to Ridge, 1 correspond to LASSO for the flag `elasticNetParam`). You can save a summary of the model to extract coefficients, intercept (bias), root mean squared error, and R2"
      ],
      "metadata": {
        "id": "4nGq2_abRUEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Train a simple LR model\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "# Select the Columns\n",
        "data_df_VA_SC = data_df_VA_SC.select(['features_scaled', 'y'])\n",
        "lr = LinearRegression(featuresCol = 'features_scaled', labelCol='y', maxIter=50)\n",
        "lr_model = lr.fit(data_df_VA_SC)\n",
        "trainingSummary = lr_model.summary\n",
        "print(\"Coefficients: \" + str(np.round(lr_model.coefficients, 4)))\n",
        "print(\"Intercept: \" + str(np.round(lr_model.intercept, 4)))\n",
        "print(\"MSE: %f\" % trainingSummary.rootMeanSquaredError**2)\n",
        "print(\"r2: %f\" % trainingSummary.r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEVljjvtRTzf",
        "outputId": "10daebf2-a792-4300-c5a0-7c30194f19d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [5.5618 5.5618]\n",
            "Intercept: 7.5005\n",
            "MSE: 4.986968\n",
            "r2: 0.956625\n"
          ]
        }
      ]
    }
  ]
}